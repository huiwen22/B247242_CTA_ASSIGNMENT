---
title: "不要的代码"
output:
  pdf_document: default
  html_document: default
  word_document: default
date: "2024-05-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rvest)
library(dplyr)
library(stringr)

extract_and_clean_text <- function(url) {
  # Attempt to read the HTML from the URL with error handling
  page <- tryCatch({
    read_html(url)
  }, error = function(e) {
    message("Failed to read HTML from URL: ", url, " with error: ", e$message)
    return(NULL)  # Return NULL on failure
  })
  
  # Proceed if the page was successfully loaded
  if (!is.null(page)) {
    # Extract text from all paragraph elements
    text_elements <- html_elements(page, "p")
    text_content <- html_text(text_elements, trim = TRUE)
    
    # Combine all paragraph texts into one single string
    combined_text <- paste(text_content, collapse = " ")
    
    # Clean the combined text
    cleaned_text <- combined_text %>%
      str_replace_all("[\\r\\n]", " ") %>%  # Replace newlines and carriage returns with space
      str_replace_all("[[:punct:]]+", " ") %>%  # Replace punctuation with space
      str_replace_all("\\s+", " ")  # Replace multiple spaces with a single space
    
    return(cleaned_text)
  } else {
    message("No page content available for URL: ", url)
    return("")  # Return empty string if no content was extracted
  }
}

# Usage example
url <- "https://www.scirp.org/journal/paperinformation?paperid=123598"
page_text <- extract_and_clean_text(url)
print(page_text)

```



```{r}
# 创建额外的停用词列表
extra_stopwords <- c("generally", "particularly", "as", "for", "since", "yet", "therefore", "additionally", "s", "m", "f", "et", "al", "e","t","a", "l", "")

# 使用 tibble() 创建额外停用词的数据框
extra_stopwords_df <- tibble(word = extra_stopwords)

# 获取默认的英文停用词列表
default_stopwords_df <- tibble(word = stopwords("en"))

# 合并自定义的和默认的停用词列表
custom_stopwords <- bind_rows(extra_stopwords_df, default_stopwords_df)
```


